{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Major Model Analysis Ahead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.model_analysis import * \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "#from nilearn import datasets, plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 384, 13, 13])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "#import torchvision.models as models\n",
    "\n",
    "# Instantiate the model\n",
    "model = torch.load('/Users/emilykruger/Documents/GitHub/aml_project_2023/hpc/utils/pretrained_alexnet.pt')\n",
    "\n",
    "# Create a dummy input\n",
    "dummy_input = torch.randn(1, 3, 224, 224)\n",
    "\n",
    "# Pass the dummy input through the model up to the layer of interest\n",
    "layer_of_interest = 6  # Change this to the index of your layer of interest\n",
    "model = torch.nn.Sequential(*(list(model.features.children())[:layer_of_interest + 1]))\n",
    "output = model(dummy_input)\n",
    "output_shape = output.shape[1] * output.shape[2] * output.shape[3]\n",
    "\n",
    "# Print the output shape\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of pca_brain:  (5, 39548)\n",
      "activation type: <class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emilykruger/Documents/GitHub/aml_project_2023/aml_project_2023/aml_venv/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (1): AdaptiveAvgPool2d(output_size=(6, 6))\n",
      ")\n",
      "Output shape of the model after removing head: 9216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emilykruger/Documents/GitHub/aml_project_2023/aml_project_2023/aml_venv/lib/python3.11/site-packages/torch/overrides.py:110: UserWarning: 'has_cuda' is deprecated, please use 'torch.backends.cuda.is_built()'\n",
      "  torch.has_cuda,\n",
      "/Users/emilykruger/Documents/GitHub/aml_project_2023/aml_project_2023/aml_venv/lib/python3.11/site-packages/torch/overrides.py:111: UserWarning: 'has_cudnn' is deprecated, please use 'torch.backends.cudnn.is_available()'\n",
      "  torch.has_cudnn,\n",
      "/Users/emilykruger/Documents/GitHub/aml_project_2023/aml_project_2023/aml_venv/lib/python3.11/site-packages/torch/overrides.py:117: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n",
      "  torch.has_mps,\n",
      "/Users/emilykruger/Documents/GitHub/aml_project_2023/aml_project_2023/aml_venv/lib/python3.11/site-packages/torch/overrides.py:118: UserWarning: 'has_mkldnn' is deprecated, please use 'torch.backends.mkldnn.is_available()'\n",
      "  torch.has_mkldnn,\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    #Change as needed\n",
    "    checkpoint_path = '/Users/emilykruger/Documents/GitHub/aml_project_2023/hpc/utils/trained_models/alexnet_LR0.00015_SAMPLES_200_EPOCHS100_BATCHSIZE_16_TIME_2023-12-07_23:18:19.pt'\n",
    "    output_size = 100\n",
    "    backbone = 'alexnet'\n",
    "    #load images and original activations\n",
    "    subject_id = 1\n",
    "    brain, image_paths = load_subject_data(1, index_start=0, index_end=5)\n",
    "\n",
    "    #pick image and activation\n",
    "    image = np.load(image_paths[0])\n",
    "    image = preprocess(image)\n",
    "\n",
    "    activation = torch.Tensor(brain[0,:])\n",
    "    print('activation type:', type(activation))\n",
    "\n",
    "    scores = {}\n",
    "\n",
    "    # Check if GPU is available and if not, use CPU\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    #Load in model & Create feature extractor\n",
    "    trained_model_state_dict = torch.load(checkpoint_path, map_location = device)\n",
    "    feature_extractor = torch.hub.load('utils', backbone, source = 'local')\n",
    "\n",
    "    trained_model = ResNet1HeadID(output_size = output_size, feature_extractor= feature_extractor).eval()\n",
    "    trained_model.load_state_dict(trained_model_state_dict[\"model_state_dict\"])\n",
    "    trained_model_backbone = trained_model.feature_extractor\n",
    "\n",
    "    if backbone == \"alexnet\":\n",
    "        output_layer_names = get_module_names(trained_model_backbone)[1:-1]\n",
    "    else:\n",
    "        output_layer_names = get_block_names(trained_model_backbone)[:-1]\n",
    "\n",
    "    feature_extractor = create_feature_extractor(trained_model_backbone, output_layer_names)\n",
    "\n",
    "    #Extract features & predict fMRI data \n",
    "    outputs = feature_extractor(image.unsqueeze(0))\n",
    "    flat_outputs = flatten_features(outputs)\n",
    "    predictions = make_prediction(trained_model, flat_outputs, output_shape, subject = subject_id)\n",
    "    print(predictions)\n",
    "\n",
    "    #Inverse transform of preds with frozen PCA models\n",
    "    pca = get_pca_model(subject_id)\n",
    "    inversed_predictions = predictions.copy()\n",
    "    for key in inversed_predictions:\n",
    "        #convert prediction tensors to np arrays to make it compatible for inverse pca\n",
    "        preds = inversed_predictions[key].detach().numpy()\n",
    "        preds = torch.Tensor(pca.inverse_transform(preds))\n",
    "        print('preds type:', type(preds))\n",
    "        # inverse-pca and store in new dict\n",
    "        inversed_predictions[key] = preds\n",
    "\n",
    "   #Caculating MNNPC on Preds\n",
    "    # for key in inversed_predictions:\n",
    "    #     preds = inversed_predictions[key]\n",
    "    #     mnnpc = MNNPC()\n",
    "    #     score = mnnpc(pred = preds, gt=activation)\n",
    "    #     scores[key] = score\n",
    "\n",
    "    # print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aml_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
